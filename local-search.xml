<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Reid相关sampler与loss详解</title>
    <link href="/2025/08/26/Reid%E7%9B%B8%E5%85%B3sampler%E4%B8%8Eloss%E8%AF%A6%E8%A7%A3/"/>
    <url>/2025/08/26/Reid%E7%9B%B8%E5%85%B3sampler%E4%B8%8Eloss%E8%AF%A6%E8%A7%A3/</url>
    
    <content type="html"><![CDATA[<h1 id="class-RandomIdentitySampler-Sampler"><a href="#class-RandomIdentitySampler-Sampler" class="headerlink" title="class RandomIdentitySampler(Sampler)"></a>class RandomIdentitySampler(Sampler)</h1><p>在数据加载器的构建中可选采样方式，当训练需要计算三元组损失的时候，采样类分析如下<br><img src="/HEXO-Editor/sampler.png"></p><h1 id="loss"><a href="#loss" class="headerlink" title="loss"></a>loss</h1><h2 id="IDloss"><a href="#IDloss" class="headerlink" title="IDloss"></a>IDloss</h2><p>计算实例</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 输入数据</span><br>inputs = torch.tensor([[<span class="hljs-number">2.0</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">0.1</span>],<br>                       [<span class="hljs-number">0.5</span>, <span class="hljs-number">3.0</span>, <span class="hljs-number">1.2</span>]])  <span class="hljs-comment"># [2, 3]</span><br>targets = torch.tensor([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>])            <span class="hljs-comment"># [2]</span><br><br><span class="hljs-comment"># Step 1: 计算log概率</span><br>log_probs = F.log_softmax(inputs, dim=<span class="hljs-number">1</span>)<br><span class="hljs-comment"># [[-0.313, -1.313, -2.213],</span><br><span class="hljs-comment">#  [-2.014, -0.514, -1.314]]</span><br><br><span class="hljs-comment"># Step 2: 创建one-hot</span><br>targets_onehot = torch.zeros(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>)<br>targets_onehot.scatter_(<span class="hljs-number">1</span>, targets.unsqueeze(<span class="hljs-number">1</span>), <span class="hljs-number">1</span>)<br><span class="hljs-comment"># [[1, 0, 0],</span><br><span class="hljs-comment">#  [0, 1, 0]]</span><br><br><span class="hljs-comment"># Step 3: 标签平滑 (epsilon=0.1, num_classes=3)</span><br>smooth_targets = <span class="hljs-number">0.9</span> * targets_onehot + <span class="hljs-number">0.1</span>/<span class="hljs-number">3</span><br><span class="hljs-comment"># [[0.9333, 0.0333, 0.0333],</span><br><span class="hljs-comment">#  [0.0333, 0.9333, 0.0333]]</span><br><br><span class="hljs-comment"># Step 4: 计算损失</span><br>loss_matrix = -smooth_targets * log_probs<br><span class="hljs-comment"># [[0.292, 0.044, 0.074],</span><br><span class="hljs-comment">#  [0.067, 0.480, 0.044]]</span><br><br><span class="hljs-comment"># 平均后求和</span><br>loss = loss_matrix.mean(<span class="hljs-number">0</span>).<span class="hljs-built_in">sum</span>()<br><span class="hljs-comment"># ≈ 1.001</span><br></code></pre></td></tr></table></figure><p>主要理解创建one-hot步骤，是根据实际类别数（例如market1501训练集中为751个类别）创建，该样本属于第几类则该位置为1。<br>其中tensor.scatter_(dim, index, value)对应操作维度，索引张量，要填入的值</p><h2 id="tripletloss"><a href="#tripletloss" class="headerlink" title="tripletloss"></a>tripletloss</h2><p>输入样例</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-comment"># 假设有6个样本，3个身份，每个身份2张图片</span><br>batch_size = <span class="hljs-number">6</span><br>feature_dim = <span class="hljs-number">128</span><br><br><span class="hljs-comment"># 特征向量 [6, 128]</span><br>global_feat = torch.tensor([<br>    [<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>, <span class="hljs-number">1.5</span>],  <span class="hljs-comment"># 样本0, 身份0</span><br>    [<span class="hljs-number">1.1</span>, <span class="hljs-number">2.1</span>, <span class="hljs-number">3.1</span>, <span class="hljs-number">1.6</span>],  <span class="hljs-comment"># 样本1, 身份0 (与样本0相似)</span><br>    [<span class="hljs-number">5.0</span>, <span class="hljs-number">6.0</span>, <span class="hljs-number">7.0</span>, <span class="hljs-number">5.5</span>],  <span class="hljs-comment"># 样本2, 身份1</span><br>    [<span class="hljs-number">5.2</span>, <span class="hljs-number">6.1</span>, <span class="hljs-number">7.2</span>, <span class="hljs-number">5.6</span>],  <span class="hljs-comment"># 样本3, 身份1 (与样本2相似)</span><br>    [<span class="hljs-number">9.0</span>, <span class="hljs-number">8.0</span>, <span class="hljs-number">7.0</span>, <span class="hljs-number">9.5</span>],  <span class="hljs-comment"># 样本4, 身份2</span><br>    [<span class="hljs-number">9.1</span>, <span class="hljs-number">8.2</span>, <span class="hljs-number">7.1</span>, <span class="hljs-number">9.6</span>],  <span class="hljs-comment"># 样本5, 身份2 (与样本4相似)</span><br>])<br><span class="hljs-comment"># 标签 [6]</span><br>labels = torch.tensor([<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>])<br><span class="hljs-comment"># 创建TripletLoss实例</span><br>triplet_loss = TripletLoss(margin=<span class="hljs-number">0.3</span>, hard_factor=<span class="hljs-number">0.1</span>)<br></code></pre></td></tr></table></figure><p><strong>步骤</strong><br>1.计算距离矩阵</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 使用欧几里得距离</span><br>dist_mat = euclidean_dist(global_feat, global_feat)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;距离矩阵 (6x6):&quot;</span>)<br><span class="hljs-built_in">print</span>(dist_mat.<span class="hljs-built_in">round</span>(<span class="hljs-number">3</span>))<span class="hljs-comment">#对数值四舍五入</span><br><br><span class="hljs-comment"># 输出示例:</span><br><span class="hljs-comment"># tensor([[0.000, 0.200, 7.348, 7.416, 12.207, 12.329],  # 样本0到各样本距离</span><br><span class="hljs-comment">#         [0.200, 0.000, 7.211, 7.279, 12.042, 12.164],  # 样本1到各样本距离</span><br><span class="hljs-comment">#         [7.348, 7.211, 0.000, 0.283, 5.099, 5.148],    # 样本2到各样本距离</span><br><span class="hljs-comment">#         [7.4pri16, 7.279, 0.283, 0.000, 4.950, 4.999],    # 样本3到各样本距离</span><br><span class="hljs-comment">#         [12.207, 12.042, 5.099, 4.950, 0.000, 0.224],  # 样本4到各样本距离</span><br><span class="hljs-comment">#         [12.329, 12.164, 5.148, 4.999, 0.224, 0.000]]) # 样本5到各样本距离</span><br></code></pre></td></tr></table></figure><p>2.创建正负样本掩码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">N = <span class="hljs-number">6</span><br>is_pos = labels.expand(N, N).eq(labels.expand(N, N).t())<br>is_neg = labels.expand(N, N).ne(labels.expand(N, N).t())<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;正样本掩码 is_pos:&quot;</span>)<br><span class="hljs-built_in">print</span>(is_pos)<br><span class="hljs-comment"># tensor([[True,  True,  False, False, False, False],  # 样本0: 与0,1同类</span><br><span class="hljs-comment">#         [True,  True,  False, False, False, False],  # 样本1: 与0,1同类</span><br><span class="hljs-comment">#         [False, False, True,  True,  False, False],  # 样本2: 与2,3同类</span><br><span class="hljs-comment">#         [False, False, True,  True,  False, False],  # 样本3: 与2,3同类</span><br><span class="hljs-comment">#         [False, False, False, False, True,  True ],  # 样本4: 与4,5同类</span><br><span class="hljs-comment">#         [False, False, False, False, True,  True ]]) # 样本5: 与4,5同类</span><br><span class="hljs-comment">#负样本掩码为正样本掩码取反</span><br></code></pre></td></tr></table></figure><p>3.困难样本挖掘</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 找到最困难的正样本（最远的正样本）</span><br>dist_ap, _ = torch.<span class="hljs-built_in">max</span>(dist_mat[is_pos].contiguous().view(N, -<span class="hljs-number">1</span>), <span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>)<br>dist_ap = dist_ap.squeeze(<span class="hljs-number">1</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;每个样本到最困难正样本的距离 dist_ap:&quot;</span>)<br><span class="hljs-built_in">print</span>(dist_ap.<span class="hljs-built_in">round</span>(<span class="hljs-number">3</span>))<br><span class="hljs-comment"># tensor([0.200, 0.200, 0.283, 0.283, 0.224, 0.224])</span><br><span class="hljs-comment"># 解释:</span><br><span class="hljs-comment"># 样本0: 最远正样本是样本1，距离0.200</span><br><span class="hljs-comment"># 样本1: 最远正样本是样本0，距离0.200</span><br><span class="hljs-comment"># 样本2: 最远正样本是样本3，距离0.283</span><br><span class="hljs-comment"># 样本3: 最远正样本是样本2，距离0.283</span><br><span class="hljs-comment"># 样本4: 最远正样本是样本5，距离0.224</span><br><span class="hljs-comment"># 样本5: 最远正样本是样本4，距离0.224</span><br><br><span class="hljs-comment"># 找到最困难的负样本（最近的负样本）</span><br>dist_an, _ = torch.<span class="hljs-built_in">min</span>(dist_mat[is_neg].contiguous().view(N, -<span class="hljs-number">1</span>), <span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>)<br>dist_an = dist_an.squeeze(<span class="hljs-number">1</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;每个样本到最困难负样本的距离 dist_an:&quot;</span>)<br><span class="hljs-built_in">print</span>(dist_an.<span class="hljs-built_in">round</span>(<span class="hljs-number">3</span>))<br><span class="hljs-comment"># tensor([7.211, 7.211, 4.950, 4.950, 7.211, 7.211])</span><br><span class="hljs-comment"># 解释:</span><br><span class="hljs-comment"># 样本0: 最近负样本距离7.211 (样本2或3中的一个)</span><br><span class="hljs-comment"># 样本1: 最近负样本距离7.211</span><br><span class="hljs-comment"># 样本2: 最近负样本距离4.950 (样本4或5中的一个)</span><br><span class="hljs-comment"># 样本3: 最近负样本距离4.950</span><br><span class="hljs-comment"># 样本4: 最近负样本距离7.211 (样本0或1中的一个)</span><br><span class="hljs-comment"># 样本5: 最近负样本距离7.211</span><br></code></pre></td></tr></table></figure><p><strong>注意</strong>：dist_ap, _ &#x3D; torch.max(dist_mat[is_pos].contiguous().view(N, -1), 1, keepdim&#x3D;True)<br>此语句中有应用要求： NOTE: Only consider the case in which all labels have same num of samples,thus we can cope with all anchors in parallel.<br>即所有ID都有相同数量的图片，由此每一个anchor都是等价的，如本列所示<br>对应到Market1501数据集上，则是一个batch64张图片，N&#x3D;64，shape[lable]&#x3D;64,每张图片有四张（含本身）是positive,一共有4x64个true,在view()后为[64,4]的形状，可在各64行找出对应的最困难样本<br>4.应用困难因子</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">hard_factor = <span class="hljs-number">0.1</span><br><br><span class="hljs-comment"># 调整距离</span><br>dist_ap_adjusted = dist_ap * (<span class="hljs-number">1.0</span> + hard_factor)  <span class="hljs-comment"># 增大正样本距离</span><br>dist_an_adjusted = dist_an * (<span class="hljs-number">1.0</span> - hard_factor)  <span class="hljs-comment"># 减小负样本距离</span><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;调整后的正样本距离:&quot;</span>)<br><span class="hljs-built_in">print</span>(dist_ap_adjusted.<span class="hljs-built_in">round</span>(<span class="hljs-number">3</span>))<br><span class="hljs-comment"># tensor([0.220, 0.220, 0.311, 0.311, 0.246, 0.246])</span><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;调整后的负样本距离:&quot;</span>)<br><span class="hljs-built_in">print</span>(dist_an_adjusted.<span class="hljs-built_in">round</span>(<span class="hljs-number">3</span>))<br><span class="hljs-comment"># tensor([6.490, 6.490, 4.455, 4.455, 6.490, 6.490])</span><br></code></pre></td></tr></table></figure><p>5.计算损失</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 创建标签y (全为1)</span><br>y = dist_an_adjusted.new().resize_as_(dist_an_adjusted).fill_(<span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;标签y:&quot;</span>, y)<br><span class="hljs-comment"># tensor([1., 1., 1., 1., 1., 1.])</span><br><br><span class="hljs-comment"># 使用MarginRankingLoss计算损失</span><br>margin = <span class="hljs-number">0.3</span><br>ranking_loss = nn.MarginRankingLoss(margin=margin)<br><br><span class="hljs-comment"># MarginRankingLoss公式: max(0, margin + x1 - x2)</span><br><span class="hljs-comment"># 这里 x1=dist_ap_adjusted, x2=dist_an_adjusted</span><br>loss = ranking_loss(dist_an_adjusted, dist_ap_adjusted, y)<br><br></code></pre></td></tr></table></figure><p>创建标签y的目的：<br>MarginRankingLoss 公式:loss &#x3D; max(0, -y * (x2 - x1) + margin)<br>本质没变：anchor到负例的距离比到正例的距离大margin才好，当负样本距离 &gt;&gt; 正样本距离 + 边界时，损失为0。</p><h2 id="对比损失，图像对文本的交叉熵"><a href="#对比损失，图像对文本的交叉熵" class="headerlink" title="对比损失，图像对文本的交叉熵"></a>对比损失，图像对文本的交叉熵</h2><iframe src="/pdfjs/web/viewer.html?file=/pdf/loss.pdf" style='width:100%;height:800px'></iframe>   ]]></content>
    
    
    <categories>
      
      <category>Projects</category>
      
      <category>CLIP_Reid_Change</category>
      
    </categories>
    
    
    <tags>
      
      <tag>loss</tag>
      
      <tag>sampler</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CLIP_Reid_Change代码解读</title>
    <link href="/2025/08/21/Clip_ReID_change/"/>
    <url>/2025/08/21/Clip_ReID_change/</url>
    
    <content type="html"><![CDATA[<h1 id="修改思路"><a href="#修改思路" class="headerlink" title="修改思路"></a>修改思路</h1><p>（1）使用qianwen-VL生成文本描述<br>（2）加入模态融合模块</p><h1 id="整体框架"><a href="#整体框架" class="headerlink" title="整体框架"></a>整体框架</h1><h2 id="make-dataloader"><a href="#make-dataloader" class="headerlink" title="make_dataloader()"></a>make_dataloader()</h2><p>数据的加载函数<br>实现：（make_dataloader_clipreid.py）<br>（1）数据集的增强，训练数据集的翻转，裁剪，填充，擦除，归一化等；测试集只有resize操作。<br>（2）采样方法，要计算三元组损失时需要对应的采样方法构成正例和负例对。<br><strong>注：market1501数据集的预处理中（market1501.py）有对训练数据集的pid进行relable,使id连续，测试集无。</strong></p><h2 id="make-model（）"><a href="#make-model（）" class="headerlink" title="make_model（）"></a>make_model（）</h2><p>实现：（make_model_clipreid.py）<br>（1）交叉注意力模块实现模态的进一步融合（复现PromptSG）<br>（2）PromptLearner类得到图像的prompt（此处使用的qianwen-VL产生的text）会对text进行长度截断，分词，得到embedding<br>（3）TextEncoder类获得文本特征,embedding作为输入加上位置编码，经过clip的transformer后取出EOS token（序列中tokenID最大的token,代表文本特征）<br>（4）build_transformer类实现模型的前向计算过程，主要包括图像特征提取backbone的选择，相机和视角信息的加入选择，是否返回融合特征的选择<br>看返回值的代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.training:<span class="hljs-comment">#训练阶段的返回值</span><br>           cls_score = <span class="hljs-variable language_">self</span>.classifier(feat)<br>           cls_score_proj = <span class="hljs-variable language_">self</span>.classifier_proj(feat_proj)<br>           <br>           <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.use_modal_fusion <span class="hljs-keyword">and</span> fused_features <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>               <span class="hljs-keyword">return</span> [cls_score, cls_score_proj], [img_feature_last, img_feature, img_feature_proj], img_feature_proj, fused_features<br>           <span class="hljs-keyword">else</span>:<br>               <span class="hljs-keyword">return</span> [cls_score, cls_score_proj], [img_feature_last, img_feature, img_feature_proj], img_feature_proj<br><br>       <span class="hljs-keyword">else</span>:<br>           <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.neck_feat == <span class="hljs-string">&#x27;after&#x27;</span>:<span class="hljs-comment">#BN后的特征在训练时用来分类，而BN前的特征在测试时用来对比</span><br>               <span class="hljs-comment"># print(&quot;Test with feature after BN&quot;)</span><br>               <span class="hljs-keyword">return</span> torch.cat([feat, feat_proj], dim=<span class="hljs-number">1</span>)<br>           <span class="hljs-keyword">else</span>:<br>               <span class="hljs-keyword">return</span> torch.cat([img_feature, img_feature_proj], dim=<span class="hljs-number">1</span>)<br><br></code></pre></td></tr></table></figure><p>模型训练模式下依次返回，[特征对应分数值（特征经过classifier得到），投影后特征对应的分数值]，[第十一层的特征，第12层的特征，最后经过投影后的特征],投影后特征，融合特征<br>在模型的评估模式下依次返回[12层特征经过BatchNormize层后的特征，12层特征投影后经过BatchNormize层后的特征]<br><strong>由此可知在进行评估时没有使用融合特征，还是用的图像特征，只是在训练时用融合特征计算损失函数优化visual encoder。需要做修改和相关实验</strong></p><h2 id="make-loss（）"><a href="#make-loss（）" class="headerlink" title="make_loss（）"></a>make_loss（）</h2><p>实现:( make_loss.py)<br>（1）在标签平滑（labelsmooth）的情况下和不使用labelsmooth的情况下计算交叉熵损失（IDloss）,三元组损失的计算<br>（2）独立的中心损失的计算<br> <strong>注：在修改之后，去掉了clip-reid中的Li2tce损失，后续可做相关的改进和实验</strong></p><h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h1><p> market1501数据集<br> baseline:<br> clip-reid<br> mAP:89.6<br> R1:95.5<br> 修改后<br> 文件名：vl_crossatten_market1501<br> mAP:88.1<br> R1:93.9</p>]]></content>
    
    
    <categories>
      
      <category>Projects</category>
      
      <category>CLIP_Reid_Change</category>
      
    </categories>
    
    
    <tags>
      
      <tag>reid</tag>
      
      <tag>code</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>HEXO Editor</title>
    <link href="/2025/03/15/HEXO-Editor/"/>
    <url>/2025/03/15/HEXO-Editor/</url>
    
    <content type="html"><![CDATA[<h3 id="问题描述："><a href="#问题描述：" class="headerlink" title="问题描述："></a>问题描述：</h3><p>1.当图像路径为public&#x2F;img时，部署路径需要含img，此时图片在hexo editor中无法预览。<br>2.截图改名需要到对应文件夹中修改</p><h3 id="解决方法："><a href="#解决方法：" class="headerlink" title="解决方法："></a>解决方法：</h3><p>1.设置图像路径指向source文件夹可解决问题<br>2.结合ctrl键修改（貌似github中没有说明这一点？我真的醉了，还以为版本问题）</p><h3 id="测试："><a href="#测试：" class="headerlink" title="测试："></a>测试：</h3><p>下面是我的测试图片<br><img src="/HEXO-Editor/my_test.png" alt="测试之桌面皮卡丘"></p>]]></content>
    
    
    <categories>
      
      <category>TOOL</category>
      
      <category>HEXO</category>
      
    </categories>
    
    
  </entry>
  
  
  
  
</search>
